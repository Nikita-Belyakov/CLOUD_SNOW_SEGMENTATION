{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b3e62b7",
   "metadata": {},
   "source": [
    "# NOTEBOOK FOR  TRAINING MANET MODEL ON ELECTRO-L №2 DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18154983",
   "metadata": {},
   "source": [
    "## IMPORT ALL REQUIRED PACKAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "12443e93",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "12443e93",
    "outputId": "d0254682-8605-49ae-896a-a488e28f909e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('11.7', '1.23.5')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchmetrics\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "import pandas as pd\n",
    "import patoolib\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "from timeit import default_timer as timer \n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import gc\n",
    "import warnings\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "from IPython.display import clear_output\n",
    "from torcheval.metrics.functional import multiclass_f1_score\n",
    "import random\n",
    "import glob\n",
    "import tifffile as tff\n",
    "from skimage.transform import resize as interp_resize\n",
    "import segmentation_models_pytorch as smp\n",
    "import torch.optim as optim\n",
    "import rasterio\n",
    "from ranger21 import Ranger21\n",
    "import kornia as K\n",
    "from kornia.augmentation.container import AugmentationSequential\n",
    "from kornia.augmentation import (\n",
    "    RandomAffine,\n",
    "    RandomElasticTransform,\n",
    "    RandomHorizontalFlip,\n",
    "    RandomPerspective,\n",
    "    RandomRotation,\n",
    "    RandomVerticalFlip)\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36883ba",
   "metadata": {},
   "source": [
    "## Initilize your current directory and device (CUDA recommended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4ced7a82",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4ced7a82",
    "outputId": "db4c076d-e0a5-47e6-b7f3-639fc4f7b751"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.set_printoptions(threshold=1e7)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "your_current_dir = os.getcwd()\n",
    "print('Your current dir of this .ipynb file',your_current_dir)\n",
    "print('Your device:',device)\n",
    "your_current_dir = your_current_dir.replace('training_model_utils','')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab50521",
   "metadata": {},
   "source": [
    "## Set random seeds for stability everywhere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b1fb9bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "seed_everything(seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d36f925",
   "metadata": {},
   "source": [
    "## Define functions for preprocessing and postprocessing multispectral data as pytorch tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1e2c98bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_to_img(xb, idx=0):\n",
    "    img = np.array(xb.squeeze(0))\n",
    "    return np.array(img.transpose((1,2,0))*255)\n",
    "def transpose_patch(patch):\n",
    "    tr = np.array(patch).astype(np.uint8).transpose((2,0,1))\n",
    "    return tr\n",
    "def predb_to_mask(predb,idx=0):\n",
    "    p = torch.functional.F.softmax(predb.squeeze(0), 0)\n",
    "    return p.argmax(0).cpu()\n",
    "def inverse_normalize(tensor,mean,std,num_shannels =5):\n",
    "    tensor = tensor.detach().cpu().numpy()\n",
    "    # unnormalize the RGB channels\n",
    "    for i in range(num_shannels):\n",
    "        tensor[i] = (tensor[i] * std[i]) + mean[i]\n",
    "    # clip values to [0, 1] range\n",
    "    tensor = np.clip(tensor, 0, 1)\n",
    "    # convert back to uint8\n",
    "    tensor = (tensor * 255).astype(np.uint8)\n",
    "    return tensor\n",
    "def open_sample_as_pil_no_norm(datacube):\n",
    "    inversed_rgb = (datacube[0:3])\n",
    "    rgb = np.dstack((inversed_rgb[2,:,:],inversed_rgb[1,:,:],inversed_rgb[0,:,:]))*255\n",
    "    return rgb.astype('uint8')\n",
    "def open_DEM(datacube):\n",
    "    dem_arr = datacube[5]#*255\n",
    "    return dem_arr.numpy()#.astype('uint8')\n",
    "def open_mask_as_pil(seglabel):\n",
    "    mask = (seglabel.numpy())\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a6603c",
   "metadata": {},
   "source": [
    "## MODEL INITIALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6bc073fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets initialize  architecture of segmentation FOR ALL 12 channels\n",
    "model = smp.MAnet(\n",
    "    encoder_name='efficientnet-b0', \n",
    "    in_channels=12,\n",
    "    classes=3,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e03264d",
   "metadata": {},
   "source": [
    "## CREATE A DATASET CLASS WITH ELECTRO-L №2 with masks from GOES, METEOSAT & Terra/MODIS for training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "b80a43e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ELECTRO_L2_Dataset_(Dataset):\n",
    "    def __init__(self, stack_dir_list,aux_dir, pytorch=True, include_BT = True,nonempty_mode = True):\n",
    "        super().__init__()\n",
    "        self.pytorch = pytorch   \n",
    "        self.nonempty_mode = nonempty_mode\n",
    "        self.include_BT = include_BT\n",
    "        self.stack_dir_list = stack_dir_list\n",
    "        self.non_empty_list = []\n",
    "        self.snowy_list = []\n",
    "        self.stack_dirs = []\n",
    "        self.stack_dirs_BT = []\n",
    "        self.all_snow_flags = []\n",
    "        self.non_empty_snow_idxs = []\n",
    "        self.non_empty_aux = []\n",
    "        self.aux_dir = aux_dir\n",
    "        total_len = 0\n",
    "        for i in range(len(self.stack_dir_list)): # iterate over number of pictures in dataset (18 now)\n",
    "            stack_dir = self.stack_dir_list[i]\n",
    "            stack_dir_BT = self.stack_dir_list[i].replace('rgb', 'BT').replace('folder_ZSA','folder_BT')\n",
    "            non_empty_idxs_dir = self.stack_dir_list[i].replace('all_patch_folder_ZSA','nonempty_idxs_folder')\n",
    "            non_empty_idxs_dir = non_empty_idxs_dir.replace('patches_rgb','nonempty_idxs')\n",
    "            snowy_idxs_dir = non_empty_idxs_dir.replace('nonempty_idxs_folder_ZSA', 'snowy_idxs_folder')\n",
    "            snowy_idxs_dir = snowy_idxs_dir.replace('nonempty', 'snowy')\n",
    "            snow_flag_array = np.load(snowy_idxs_dir+'.npy')\n",
    "            self.all_snow_flags.append(snow_flag_array)\n",
    "            if self.nonempty_mode:\n",
    "                non_empty_idxs = np.load(non_empty_idxs_dir+'.npy')\n",
    "                snow_idxs_nonempty = np.zeros(len(snow_flag_array))\n",
    "                snow_idxs_nonempty[non_empty_idxs]=1\n",
    "                snow_idxs_nonempty = (snow_idxs_nonempty*snow_flag_array).astype(np.uint8)\n",
    "                for j in range(len(non_empty_idxs)):\n",
    "                    idx_ = non_empty_idxs[j]\n",
    "                    if snow_idxs_nonempty[idx_] == 1:\n",
    "                        self.non_empty_snow_idxs.append(total_len+j)\n",
    "                    patch_file = f\"{stack_dir}/patch_{idx_}.tif\"\n",
    "                    self.stack_dirs.append(patch_file)\n",
    "                    patch_file_BT = f\"{stack_dir_BT}/patch_{idx_}.tif\"\n",
    "                    self.stack_dirs_BT.append(patch_file_BT)\n",
    "                    self.non_empty_aux.append(idx_)\n",
    "                total_len = total_len+len(non_empty_idxs)\n",
    "            else:\n",
    "                patch_files = glob.glob(stack_dir+'/*')\n",
    "                patch_files_BT = glob.glob(stack_dir_BT+'/*')\n",
    "                for patch_file in patch_files:\n",
    "                    self.stack_dirs.append(patch_file)\n",
    "                for patch_file_BT in patch_files_BT:\n",
    "                    self.stack_dirs_BT.append(patch_file_BT) \n",
    "        self.all_snow_flags_nonempty =np.zeros(total_len).astype(np.uint8)\n",
    "        self.all_snow_flags_nonempty[self.non_empty_snow_idxs]=1\n",
    "        self.all_snow_flags = np.array(self.all_snow_flags).flatten()\n",
    "        \n",
    "    def __len__(self):\n",
    "        num_patches = int((len(self.stack_dirs))) \n",
    "        return num_patches\n",
    "    \n",
    "    def open_rgb_normed(self, idx, invert=False):\n",
    "        patch_file = self.stack_dirs[idx]\n",
    "        patch = tff.imread(patch_file)\n",
    "        r,g,b = patch[:,:,0]/255, patch[:,:,1]/255, patch[:,:,2]/255\n",
    "        patch_normed  = np.dstack([b, g ,r])\n",
    "        return patch_normed \n",
    "    \n",
    "    def open_BT_normed(self, idx, invert=False):\n",
    "        patch_file_BT = self.stack_dirs_BT[idx]\n",
    "        patch_BT = tff.imread(patch_file_BT)\n",
    "        return patch_BT \n",
    "    \n",
    "    def open_aux(self, idx, invert=False):\n",
    "        patch_file = self.aux_dir+'/patch_'+str(self.non_empty_aux[idx])+'.tif'\n",
    "        patch = tff.imread(patch_file)\n",
    "        lon,lat,dem = patch[:,:,0],patch[:,:,1],patch[:,:,2]\n",
    "        lon,lat = (lon+180.0)/360.0,(lat+90.0)/180.0\n",
    "        dem = dem/10000\n",
    "        lonlatdem_normed = np.dstack([lon,lat,dem])\n",
    "        return lonlatdem_normed\n",
    "    \n",
    "    def open_mask(self, idx):\n",
    "        patch_file = self.stack_dirs[idx]\n",
    "        mask_file = patch_file.replace('rgb','masks').replace('tif','jpg').replace('all_patch_folder_ZSA','all_masks_folder')\n",
    "        mask = tff.imread(mask_file)\n",
    "        snow_mask = mask[:,:,1]//255 #  1 - snow class\n",
    "        cloud_mask = mask[:,:,0] # 2 - cloud class\n",
    "        cloud_mask[cloud_mask!=0] = 2\n",
    "        bg = mask[:,:,2]\n",
    "        bin_mask = snow_mask + cloud_mask\n",
    "        return bin_mask\n",
    "    \n",
    "    def open_as_pil(self, idx):\n",
    "        patch_file = self.stack_dirs[idx]\n",
    "        patch_image = tff.imread(patch_file)\n",
    "        return patch_image \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        patch_file = self.stack_dirs[idx]\n",
    "        mask_file = patch_file.replace('rgb','masks').replace('tif','jpg').replace('all_patch_folder_ZSA','all_masks_folder')\n",
    "        mask = tff.imread(mask_file)\n",
    "        snow_mask = mask[:,:,1]//255 #  1 - snow class\n",
    "        cloud_mask = mask[:,:,0] # 2 - cloud class\n",
    "        cloud_mask[cloud_mask!=0]=2\n",
    "        bin_mask = snow_mask+cloud_mask\n",
    "        patch = tff.imread(patch_file)\n",
    "        r,g,b = patch[:,:,0]/255, patch[:,:,1]/255, patch[:,:,2]/255\n",
    "        aux_file = self.aux_dir+'/patch_'+str(self.non_empty_aux[idx])+'.tif'\n",
    "        aux = tff.imread(aux_file)\n",
    "        lon,lat,dem = aux[:,:,0],aux[:,:,1],aux[:,:,2]\n",
    "        lon,lat = (lon+180.0)/360.0,(lat+90.0)/180.0\n",
    "        dem = dem/10000\n",
    "        aux_normed = np.stack([lon, lat, dem])\n",
    "        patch_normed  = np.stack([b, g ,r])\n",
    "        if self.include_BT:\n",
    "            patch_file_BT = self.stack_dirs_BT[idx] \n",
    "            BT_normed = tff.imread(patch_file_BT).transpose(2,0,1)\n",
    "            full_stack = np.concatenate((patch_normed, BT_normed, aux_normed), axis=0)\n",
    "            # order of channels: b, g, r, BT4, BT5, BT6, BT7, BT8, BT9, lon, lat, dem\n",
    "            full_stack = torch.tensor(full_stack, dtype=torch.float32)\n",
    "        else:\n",
    "            full_stack = np.concatenate((patch_normed, aux_normed), axis=0)\n",
    "            full_stack = torch.tensor(full_stack, dtype=torch.float32)\n",
    "        return full_stack, torch.tensor(bin_mask).long()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc364604",
   "metadata": {},
   "source": [
    "## DEFINE A PIPELINE CLASS OF GEOMETRIC TRANSFORM ON GPU USING Kornia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "66a5a05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kornia as K\n",
    "from kornia.augmentation.container import AugmentationSequential\n",
    "class Geom_Augmentation(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Geom_Augmentation, self).__init__()\n",
    "        # we define and cache our operators as class members\n",
    "        self.augs = AugmentationSequential(\n",
    "                    RandomVerticalFlip(p=1),\n",
    "                    RandomHorizontalFlip(p=1),\n",
    "                    RandomPerspective(0.25, sampling_method = 'area_preserving', p=1.),\n",
    "                    RandomAffine(degrees =(-85.0,85.0),translate = None,scale = (0.9, 1.1),resample=\"nearest\",shear = None,padding_mode=\"reflection\",align_corners=True,same_on_batch=False,keepdim=True,p=1),\n",
    "                    RandomElasticTransform(kernel_size=(33, 33), sigma=(6.0, 6.0), alpha=(1.0, 1.0), align_corners=True, resample='nearest', padding_mode='reflection', same_on_batch=False, p=1.0, keepdim=True),\n",
    "                    data_keys=['input', 'mask'], same_on_batch = False, random_apply = 2)                       \n",
    "    def forward(self, img: torch.Tensor, mask: torch.Tensor) -> torch.Tensor:\n",
    "        # 2. apply geometric tranform\n",
    "        out = self.augs(img, mask)\n",
    "        img_out, mask_out = out[0],out[1]\n",
    "        return img_out, mask_out\n",
    "geom_augs = Geom_Augmentation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ced59c",
   "metadata": {},
   "source": [
    "## USE WEIGHTED SAMPLER TO MAKE DATALOADER MORE BALANCED WITH SNOW PATCHES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc63e7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SAMPLER FOR ELECTRO L2 DS FOR FINETUNNING\n",
    "Electro_ds_tr, Electro_ds_val  = torch.utils.data.random_split(Electro_ds, (0.8,0.2))\n",
    "non_empty_snow_patches_ds = Electro_ds_tr.all_snow_flags_nonempty\n",
    "num_non_empty_snow_patches = len(non_empty_snow_patches_ds)\n",
    "bg_weight = num_non_empty_snow_patches/len(Electro_ds_tr)\n",
    "snowy_weight = 1 - num_non_empty_snow_patches/len(Electro_ds_tr)\n",
    "batch_size = 16\n",
    "_, counts = torch.unique(torch.tensor(non_empty_snow_patches_ds), return_counts=True)\n",
    "weights = counts.max() / counts\n",
    "print(\"Weights: \", weights)\n",
    "weight_for_sampler_l2 = []  # Every sample must have a weight\n",
    "for snow_flag in non_empty_snow_patches_ds:\n",
    "    weight_for_sampler_l2.append(weights[snow_flag].item())\n",
    "sampler_l2 = WeightedRandomSampler(torch.tensor(weight_for_sampler_l2), len(Electro_ds_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "75f658a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11789, 1687, 1590)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 16 #16 # try to set as max as possible\n",
    "train_dl_ = DataLoader(Electro_ds_tr, batch_size=batch_size, sampler = sampler_l2)\n",
    "val_dl_ = DataLoader(Electro_ds_val, batch_size=batch_size, shuffle= False)\n",
    "len(Electro_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372b6cec",
   "metadata": {},
   "source": [
    "## Define function for train 1 epoch and saving best model according IoU metric value on validation subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "YqeHetID_8jy",
   "metadata": {
    "id": "YqeHetID_8jy"
   },
   "outputs": [],
   "source": [
    "def save_best_model(model,epoch,path =  r'H:/ELECTRO_DATASET/4_km_res/L2/models/MAnet_Efficient_b0_12_inputs_4km_res_ep_'):\n",
    "        model_copy = deepcopy(model)\n",
    "        best_model = model_copy\n",
    "        best_model_name = path+str(epoch)\n",
    "        torch.save(best_model.state_dict(),best_model_name)\n",
    "        print('best model is on epoch =',epoch)\n",
    "        return best_model\n",
    "def train_ep(model, train_dataload, valid_dataload, dice, focal,focal_alpha, optimizer,ep_i, best_valid_iou, scheduler =None):    \n",
    "    model.cuda()#cuda()\n",
    "    print('epoch_n =',ep_i)\n",
    "    model.train(True)  # Set train mode = true\n",
    "    step = 0\n",
    "    train_loss = 0\n",
    "    #initialize metrics\n",
    "    train_f1_score = torchmetrics.F1Score(num_classes=3, task = 'multiclass', average = 'macro').cuda()\n",
    "    train_iou_score = torchmetrics.JaccardIndex(num_classes=3, task = 'multiclass').cuda()\n",
    "    train_f1_score_sep = torchmetrics.F1Score(num_classes=3, task = 'multiclass', average = None).cuda()\n",
    "    train_iou_score_sep = torchmetrics.JaccardIndex(num_classes=3, task = 'multiclass', average = None).cuda()\n",
    "    val_f1_score = torchmetrics.F1Score(num_classes=3, task = 'multiclass', average = 'macro').cuda()\n",
    "    val_iou_score = torchmetrics.JaccardIndex(num_classes=3, task = 'multiclass').cuda()\n",
    "    val_f1_score_sep = torchmetrics.F1Score(num_classes=3, task = 'multiclass', average = None).cuda()\n",
    "    val_iou_score_sep = torchmetrics.JaccardIndex(num_classes=3, task = 'multiclass', average = None).cuda()\n",
    "    val_acc = torchmetrics.Accuracy(num_classes=3, task = 'multiclass').cuda()\n",
    "    # iterate over data\n",
    "    print('-----------training process---------')\n",
    "    for x,y in tqdm(train_dataload): \n",
    "        x = torch.tensor(x).type(torch.float32).cuda()\n",
    "        y = torch.tensor(y).type(torch.float32).cuda()\n",
    "        #add geom augmentations on GPU from kornia\n",
    "        x, y = geom_augs(x, y.unsqueeze(1)) #convert labels to float32 for kornia !!!!\n",
    "        y = y.type(torch.LongTensor).squeeze(1).cuda() #convert labels to Long again for model !!!!\n",
    "        step += 1\n",
    "        # vector graph of training with grad on CUDA\n",
    "        optimizer.zero_grad()\n",
    "        output = model(x)\n",
    "        output = torch.functional.F.softmax(output, 1)\n",
    "        predictions = output.argmax(dim=1).cuda()\n",
    "        loss = (1-focal_alpha)*dice(output, y)+focal_alpha*focal(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # other things can be done on CPU\n",
    "        loss = loss.detach()\n",
    "        predictions, y = predictions.detach(), y.detach()\n",
    "        train_f1_score.update(predictions, y)\n",
    "        train_iou_score.update(predictions, y)\n",
    "        train_f1_score_sep.update(predictions, y)\n",
    "        train_iou_score_sep.update(predictions, y)\n",
    "        train_loss=train_loss+loss\n",
    "        x,y = None, None\n",
    "        # need for torch.no_grad in this training pass\n",
    "        if scheduler!=None:\n",
    "            scheduler.step()\n",
    "    train_loss = train_loss.cpu()/len(train_dataload)\n",
    "    print('after training epoch mean train loss =',train_loss)\n",
    "    # Compute the train metrics for the epoch\n",
    "    train_f1 = train_f1_score.compute()\n",
    "    train_iou = train_iou_score.compute()\n",
    "    train_f1_sep = train_f1_score_sep.compute()\n",
    "    train_iou_sep = train_iou_score_sep.compute()\n",
    "\n",
    "    # Reset the train metrics objects for the next epoch\n",
    "    train_f1_score.reset()\n",
    "    train_iou_score.reset()\n",
    "    train_f1_score_sep.reset()\n",
    "    train_iou_score_sep.reset()\n",
    "# Inside your epoch training loop, after each batch is processed, compute the metrics on the batch predictions and ground truth\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0\n",
    "        print('-----------validation process---------')\n",
    "        for x,y in tqdm(valid_dataload):\n",
    "            x = x.cuda()#.cuda()\n",
    "            y = y.type(torch.LongTensor).cuda()\n",
    "            output = model(x)\n",
    "            output = torch.functional.F.softmax(output, 1)\n",
    "            # Assuming output has shape (batch_size, num_classes, height, width)\n",
    "            # Convert the output to predictions by taking the argmax along the channel dimension\n",
    "            predictions = output.argmax(dim=1).cuda()\n",
    "            valid_loss = (1-focal_alpha)*dice(output, y)+focal_alpha*focal(output, y)\n",
    "            val_loss = val_loss+valid_loss\n",
    "            val_f1_score.update(predictions, y)\n",
    "            val_iou_score.update(predictions, y)\n",
    "            val_f1_score_sep.update(predictions, y)\n",
    "            val_iou_score_sep.update(predictions, y)\n",
    "            val_acc.update(predictions, y)\n",
    "            x,y = None, None\n",
    "        val_f1 = val_f1_score.compute()\n",
    "        val_iou = val_iou_score.compute()\n",
    "        val_acc_ = val_acc.compute()\n",
    "        #calculate the same metrics seperately for each class\n",
    "        val_f1_sep = val_f1_score_sep.compute()\n",
    "        val_iou_sep = val_iou_score_sep.compute()\n",
    "        FAR = 1 - val_acc_\n",
    "            \n",
    "        # Compute the validation metrics for the epoch\n",
    "        val_loss = val_loss.cpu()/(len(valid_dataload))\n",
    "        print('valid loss =',val_loss)\n",
    "\n",
    "        # Reset the validation metrics objects for the next epoch\n",
    "        val_f1_score.reset()\n",
    "        val_iou_score.reset()\n",
    "        val_f1_score_sep.reset()\n",
    "        val_iou_score_sep.reset()\n",
    "        val_acc.reset()\n",
    "        # Print the F1 score and IoU for the current epoch on the train and validation sets\n",
    "        print('######### METRICS AFTER TRAINING EPOCH #########')\n",
    "        print(f\"Epoch {ep_i}, Train F1 score: {train_f1:.4f}, Train IoU: {train_iou:.4f}, Val F1 score: {val_f1:.4f}, Val IoU: {val_iou:.4f}\")\n",
    "        print(f\"Train F1 score for each class: {train_f1_sep.cpu().numpy()}, \\nTrain IoU for each class: {train_iou_sep.cpu().numpy()}\")\n",
    "        print(f\"Test FAR: {FAR:.4f}\")\n",
    "        print(f\"Test F1 score for each class: {val_f1_sep.cpu().numpy()}, \\nTest IoU for each class: {val_iou_sep.cpu().numpy()}\")\n",
    "        if (best_valid_iou<val_iou) or (val_iou>0.75):\n",
    "            save_best_model(model,ep_i)\n",
    "            print(\" model updated\")\n",
    "        return train_f1.cpu(),train_iou.cpu(),val_f1.cpu(),val_iou.cpu(), train_loss.cpu(), val_loss.cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8812c150",
   "metadata": {},
   "source": [
    "## Train loop MANet ELECTRO-L №2 data with Ranger21 optimizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "92c52f1b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranger21 optimizer ready with following settings:\n",
      "\n",
      "Core optimizer = AdamW\n",
      "Learning rate of 0.001\n",
      "\n",
      "Important - num_epochs of training = ** 30 epochs **\n",
      "please confirm this is correct or warmup and warmdown will be off\n",
      "\n",
      "Warm-up: linear warmup, over 2000 iterations\n",
      "\n",
      "Lookahead active, merging every 5 steps, with blend factor of 0.5\n",
      "Norm Loss active, factor = 0.0001\n",
      "Stable weight decay of 0.0001\n",
      "Gradient Centralization = On\n",
      "\n",
      "Adaptive Gradient Clipping = True\n",
      "\tclipping value of 0.01\n",
      "\tsteps for clipping = 0.001\n",
      "\n",
      "Warm-down: Linear warmdown, starting at 72.0%, iteration 8229 of 11430\n",
      "warm down will decay until 3e-05 lr\n",
      "epoch_n = 0\n",
      "-----------training process---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▏                                                                                 | 1/381 [00:08<55:15,  8.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params size saved\n",
      "total param groups = 1\n",
      "total params in groups = 307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 381/381 [08:39<00:00,  1.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after training epoch mean train loss = tensor(0.6554)\n",
      "-----------validation process---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 74/74 [01:23<00:00,  1.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid loss = tensor(0.5764)\n",
      "######### METRICS AFTER TRAINING EPOCH #########\n",
      "Epoch 0, Train F1 score: 0.4236, Train IoU: 0.3037, Val F1 score: 0.5324, Val IoU: 0.4349\n",
      "Train F1 score for each class: [0.6406687  0.03829631 0.59187484], \n",
      "Train IoU for each class: [0.4713117  0.01952197 0.4203283 ]\n",
      "Test FAR: 0.2333\n",
      "Test F1 score for each class: [0.7897525  0.02848086 0.7788766 ], \n",
      "Test IoU for each class: [0.6525544  0.01444615 0.6378361 ]\n",
      "epoch_n = 1\n",
      "-----------training process---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 381/381 [07:14<00:00,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after training epoch mean train loss = tensor(0.5332)\n",
      "-----------validation process---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 74/74 [00:29<00:00,  2.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid loss = tensor(0.5272)\n",
      "######### METRICS AFTER TRAINING EPOCH #########\n",
      "Epoch 1, Train F1 score: 0.5776, Train IoU: 0.4965, Val F1 score: 0.5377, Val IoU: 0.4489\n",
      "Train F1 score for each class: [0.8599661  0.03866352 0.8341346 ], \n",
      "Train IoU for each class: [0.7543337  0.01971284 0.71546376]\n",
      "Test FAR: 0.1994\n",
      "Test F1 score for each class: [0.8089161  0.00533867 0.7987582 ], \n",
      "Test IoU for each class: [0.6791428  0.00267648 0.66494375]\n",
      "epoch_n = 2\n",
      "-----------training process---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 381/381 [06:38<00:00,  1.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after training epoch mean train loss = tensor(0.5078)\n",
      "-----------validation process---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 74/74 [00:28<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid loss = tensor(0.5153)\n",
      "######### METRICS AFTER TRAINING EPOCH #########\n",
      "Epoch 2, Train F1 score: 0.5740, Train IoU: 0.5040, Val F1 score: 0.5428, Val IoU: 0.4577\n",
      "Train F1 score for each class: [8.7347227e-01 3.6097856e-04 8.4824526e-01], \n",
      "Train IoU for each class: [7.7536672e-01 1.8052186e-04 7.3648071e-01]\n",
      "Test FAR: 0.1889\n",
      "Test F1 score for each class: [8.1708777e-01 1.3815110e-04 8.1117904e-01], \n",
      "Test IoU for each class: [6.9074255e-01 6.9080321e-05 6.8233907e-01]\n",
      "epoch_n = 3\n",
      "-----------training process---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 381/381 [06:25<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after training epoch mean train loss = tensor(0.5035)\n",
      "-----------validation process---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 74/74 [00:29<00:00,  2.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid loss = tensor(0.5088)\n",
      "######### METRICS AFTER TRAINING EPOCH #########\n",
      "Epoch 3, Train F1 score: 0.5765, Train IoU: 0.5078, Val F1 score: 0.5486, Val IoU: 0.4659\n",
      "Train F1 score for each class: [8.740845e-01 2.483866e-05 8.552733e-01], \n",
      "Train IoU for each class: [7.7633220e-01 1.2419484e-05 7.4714208e-01]\n",
      "Test FAR: 0.1805\n",
      "Test F1 score for each class: [8.2391238e-01 4.5828699e-04 8.2138854e-01], \n",
      "Test IoU for each class: [7.0055360e-01 2.2919601e-04 6.9691217e-01]\n",
      "epoch_n = 4\n",
      "-----------training process---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 381/381 [06:11<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after training epoch mean train loss = tensor(0.5011)\n",
      "-----------validation process---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 74/74 [00:28<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid loss = tensor(0.5097)\n",
      "######### METRICS AFTER TRAINING EPOCH #########\n",
      "Epoch 4, Train F1 score: 0.5786, Train IoU: 0.5112, Val F1 score: 0.5463, Val IoU: 0.4624\n",
      "Train F1 score for each class: [8.7675446e-01 3.2855649e-05 8.5915118e-01], \n",
      "Train IoU for each class: [7.8055441e-01 1.6428094e-05 7.5308067e-01]\n",
      "Test FAR: 0.1842\n",
      "Test F1 score for each class: [0.8229123 0.0010144 0.814825 ], \n",
      "Test IoU for each class: [6.9910884e-01 5.0745520e-04 6.8751448e-01]\n",
      "epoch_n = 5\n",
      "-----------training process---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|████████████████████▍                                                            | 96/381 [01:32<04:37,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "** Ranger21 update = Warmup complete - lr set to 0.001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 381/381 [06:01<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after training epoch mean train loss = tensor(0.4991)\n",
      "-----------validation process---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 74/74 [00:28<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid loss = tensor(0.5041)\n",
      "######### METRICS AFTER TRAINING EPOCH #########\n",
      "Epoch 5, Train F1 score: 0.5883, Train IoU: 0.5183, Val F1 score: 0.5815, Val IoU: 0.4879\n",
      "Train F1 score for each class: [0.8789801  0.02248845 0.8633402 ], \n",
      "Train IoU for each class: [0.7840897  0.01137209 0.7595414 ]\n",
      "Test FAR: 0.1735\n",
      "Test F1 score for each class: [0.8298617  0.08375003 0.8309041 ], \n",
      "Test IoU for each class: [0.7091997  0.04370517 0.71072364]\n",
      "epoch_n = 6\n",
      "-----------training process---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 381/381 [05:57<00:00,  1.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after training epoch mean train loss = tensor(0.4964)\n",
      "-----------validation process---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 74/74 [00:28<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid loss = tensor(0.5011)\n",
      "######### METRICS AFTER TRAINING EPOCH #########\n",
      "Epoch 6, Train F1 score: 0.6438, Train IoU: 0.5520, Val F1 score: 0.5979, Val IoU: 0.5007\n",
      "Train F1 score for each class: [0.8846987  0.18098597 0.865662  ], \n",
      "Train IoU for each class: [0.79323745 0.09949674 0.76314294]\n",
      "Test FAR: 0.1680\n",
      "Test F1 score for each class: [0.8346187  0.1209437  0.83820105], \n",
      "Test IoU for each class: [0.71617645 0.06436406 0.7214682 ]\n",
      "best model is on epoch = 6\n",
      " model updated\n",
      "epoch_n = 7\n",
      "-----------training process---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 381/381 [05:55<00:00,  1.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after training epoch mean train loss = tensor(0.4936)\n",
      "-----------validation process---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 74/74 [00:29<00:00,  2.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid loss = tensor(0.5025)\n",
      "######### METRICS AFTER TRAINING EPOCH #########\n",
      "Epoch 7, Train F1 score: 0.6881, Train IoU: 0.5829, Val F1 score: 0.6047, Val IoU: 0.5030\n",
      "Train F1 score for each class: [0.8869419  0.30686718 0.87038076], \n",
      "Train IoU for each class: [0.79685146 0.18124224 0.7705081 ]\n",
      "Test FAR: 0.1701\n",
      "Test F1 score for each class: [0.8361141  0.14660276 0.83144087], \n",
      "Test IoU for each class: [0.71838146 0.07909948 0.7115094 ]\n",
      "best model is on epoch = 7\n",
      " model updated\n",
      "epoch_n = 8\n",
      "-----------training process---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 381/381 [05:50<00:00,  1.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after training epoch mean train loss = tensor(0.4923)\n",
      "-----------validation process---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 74/74 [00:28<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid loss = tensor(0.4983)\n",
      "######### METRICS AFTER TRAINING EPOCH #########\n",
      "Epoch 8, Train F1 score: 0.6995, Train IoU: 0.5922, Val F1 score: 0.6075, Val IoU: 0.5097\n",
      "Train F1 score for each class: [0.88804126 0.33723706 0.87332106], \n",
      "Train IoU for each class: [0.79862773 0.20281729 0.7751286 ]\n",
      "Test FAR: 0.1626\n",
      "Test F1 score for each class: [0.8383981  0.13809136 0.8460943 ], \n",
      "Test IoU for each class: [0.7217603  0.07416655 0.7332439 ]\n",
      "best model is on epoch = 8\n",
      " model updated\n",
      "epoch_n = 9\n",
      "-----------training process---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 381/381 [05:47<00:00,  1.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after training epoch mean train loss = tensor(0.4917)\n",
      "-----------validation process---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 74/74 [00:28<00:00,  2.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid loss = tensor(0.4995)\n",
      "######### METRICS AFTER TRAINING EPOCH #########\n",
      "Epoch 9, Train F1 score: 0.7133, Train IoU: 0.6027, Val F1 score: 0.6082, Val IoU: 0.5085\n",
      "Train F1 score for each class: [0.8891569  0.37754267 0.87329364], \n",
      "Train IoU for each class: [0.80043423 0.23269807 0.7750855 ]\n",
      "Test FAR: 0.1651\n",
      "Test F1 score for each class: [0.839938   0.14555001 0.83920634], \n",
      "Test IoU for each class: [0.72404563 0.07848689 0.72295904]\n",
      "epoch_n = 10\n",
      "-----------training process---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 381/381 [05:48<00:00,  1.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after training epoch mean train loss = tensor(0.4909)\n",
      "-----------validation process---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 74/74 [00:28<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid loss = tensor(0.5067)\n",
      "######### METRICS AFTER TRAINING EPOCH #########\n",
      "Epoch 10, Train F1 score: 0.7227, Train IoU: 0.6103, Val F1 score: 0.6022, Val IoU: 0.4965\n",
      "Train F1 score for each class: [0.8908566  0.40424538 0.87292475], \n",
      "Train IoU for each class: [0.8031935  0.25332552 0.7745045 ]\n",
      "Test FAR: 0.1785\n",
      "Test F1 score for each class: [0.8320855  0.15608314 0.81831086], \n",
      "Test IoU for each class: [0.712454  0.0846476 0.6924925]\n",
      "epoch_n = 11\n",
      "-----------training process---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 381/381 [05:47<00:00,  1.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after training epoch mean train loss = tensor(0.4900)\n",
      "-----------validation process---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 74/74 [00:28<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid loss = tensor(0.4970)\n",
      "######### METRICS AFTER TRAINING EPOCH #########\n",
      "Epoch 11, Train F1 score: 0.7274, Train IoU: 0.6150, Val F1 score: 0.6251, Val IoU: 0.5214\n",
      "Train F1 score for each class: [0.89157045 0.4149957  0.87572634], \n",
      "Train IoU for each class: [0.8043548  0.26182625 0.7789263 ]\n",
      "Test FAR: 0.1599\n",
      "Test F1 score for each class: [0.84142625 0.18626893 0.84749585], \n",
      "Test IoU for each class: [0.7262603  0.10269931 0.7353517 ]\n",
      "best model is on epoch = 11\n",
      " model updated\n",
      "epoch_n = 12\n",
      "-----------training process---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 381/381 [05:45<00:00,  1.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after training epoch mean train loss = tensor(0.4890)\n",
      "-----------validation process---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 74/74 [00:28<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid loss = tensor(0.4974)\n",
      "######### METRICS AFTER TRAINING EPOCH #########\n",
      "Epoch 12, Train F1 score: 0.7334, Train IoU: 0.6207, Val F1 score: 0.6106, Val IoU: 0.5126\n",
      "Train F1 score for each class: [0.89251006 0.42972192 0.8780094 ], \n",
      "Train IoU for each class: [0.8058855  0.27365977 0.7825461 ]\n",
      "Test FAR: 0.1605\n",
      "Test F1 score for each class: [0.84003913 0.14385587 0.8479794 ], \n",
      "Test IoU for each class: [0.72419614 0.07750253 0.73608017]\n",
      "epoch_n = 13\n",
      "-----------training process---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 381/381 [05:47<00:00,  1.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after training epoch mean train loss = tensor(0.4885)\n",
      "-----------validation process---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 74/74 [00:29<00:00,  2.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid loss = tensor(0.4957)\n",
      "######### METRICS AFTER TRAINING EPOCH #########\n",
      "Epoch 13, Train F1 score: 0.7370, Train IoU: 0.6240, Val F1 score: 0.6169, Val IoU: 0.5183\n",
      "Train F1 score for each class: [0.89302444 0.43890026 0.87896854], \n",
      "Train IoU for each class: [0.80672455 0.28114814 0.78407127]\n",
      "Test FAR: 0.1567\n",
      "Test F1 score for each class: [0.8434618  0.15598525 0.8512515 ], \n",
      "Test IoU for each class: [0.72929883 0.08459002 0.7410251 ]\n",
      "epoch_n = 14\n",
      "-----------training process---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 381/381 [05:45<00:00,  1.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after training epoch mean train loss = tensor(0.4874)\n",
      "-----------validation process---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 74/74 [00:28<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid loss = tensor(0.4980)\n",
      "######### METRICS AFTER TRAINING EPOCH #########\n",
      "Epoch 14, Train F1 score: 0.7417, Train IoU: 0.6288, Val F1 score: 0.6091, Val IoU: 0.5113\n",
      "Train F1 score for each class: [0.89570165 0.44990993 0.87961656], \n",
      "Train IoU for each class: [0.8111048  0.2902476  0.78510314]\n",
      "Test FAR: 0.1617\n",
      "Test F1 score for each class: [0.84287477 0.14079162 0.8437271 ], \n",
      "Test IoU for each class: [0.72842133 0.07572665 0.7296955 ]\n",
      "epoch_n = 15\n",
      "-----------training process---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 381/381 [05:43<00:00,  1.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after training epoch mean train loss = tensor(0.4876)\n",
      "-----------validation process---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 74/74 [00:29<00:00,  2.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid loss = tensor(0.5006)\n",
      "######### METRICS AFTER TRAINING EPOCH #########\n",
      "Epoch 15, Train F1 score: 0.7398, Train IoU: 0.6272, Val F1 score: 0.6053, Val IoU: 0.5058\n",
      "Train F1 score for each class: [0.8945906  0.44409084 0.8806756 ], \n",
      "Train IoU for each class: [0.80928457 0.2854221  0.7867919 ]\n",
      "Test FAR: 0.1658\n",
      "Test F1 score for each class: [0.8375941  0.14001456 0.83818233], \n",
      "Test IoU for each class: [0.7205693  0.07527724 0.72144043]\n",
      "epoch_n = 16\n",
      "-----------training process---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 381/381 [05:46<00:00,  1.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after training epoch mean train loss = tensor(0.4857)\n",
      "-----------validation process---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 74/74 [00:28<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid loss = tensor(0.4941)\n",
      "######### METRICS AFTER TRAINING EPOCH #########\n",
      "Epoch 16, Train F1 score: 0.7457, Train IoU: 0.6337, Val F1 score: 0.6256, Val IoU: 0.5253\n",
      "Train F1 score for each class: [0.8967649  0.45538533 0.88484263], \n",
      "Train IoU for each class: [0.81285024 0.2948213  0.7934688 ]\n",
      "Test FAR: 0.1545\n",
      "Test F1 score for each class: [0.84503794 0.17655528 0.8553564 ], \n",
      "Test IoU for each class: [0.7316586  0.09682513 0.7472686 ]\n",
      "best model is on epoch = 16\n",
      " model updated\n",
      "epoch_n = 17\n",
      "-----------training process---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 381/381 [05:46<00:00,  1.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after training epoch mean train loss = tensor(0.4869)\n",
      "-----------validation process---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 74/74 [00:29<00:00,  2.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid loss = tensor(0.5073)\n",
      "######### METRICS AFTER TRAINING EPOCH #########\n",
      "Epoch 17, Train F1 score: 0.7468, Train IoU: 0.6334, Val F1 score: 0.6040, Val IoU: 0.4978\n",
      "Train F1 score for each class: [0.8960391  0.46353155 0.8807085 ], \n",
      "Train IoU for each class: [0.81165844 0.30168635 0.78684473]\n",
      "Test FAR: 0.1806\n",
      "Test F1 score for each class: [0.83190525 0.16113098 0.818993  ], \n",
      "Test IoU for each class: [0.71218985 0.08762505 0.69347006]\n",
      "epoch_n = 18\n",
      "-----------training process---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 381/381 [05:42<00:00,  1.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after training epoch mean train loss = tensor(0.4860)\n",
      "-----------validation process---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 74/74 [00:29<00:00,  2.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid loss = tensor(0.4930)\n",
      "######### METRICS AFTER TRAINING EPOCH #########\n",
      "Epoch 18, Train F1 score: 0.7495, Train IoU: 0.6364, Val F1 score: 0.6188, Val IoU: 0.5222\n",
      "Train F1 score for each class: [0.89617085 0.46882227 0.8834866 ], \n",
      "Train IoU for each class: [0.81187457 0.30618408 0.7912907 ]\n",
      "Test FAR: 0.1518\n",
      "Test F1 score for each class: [0.84697133 0.15263656 0.8567538 ], \n",
      "Test IoU for each class: [0.73456216 0.082624   0.74940455]\n",
      "epoch_n = 19\n",
      "-----------training process---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 381/381 [05:43<00:00,  1.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after training epoch mean train loss = tensor(0.4855)\n",
      "-----------validation process---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 74/74 [00:28<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid loss = tensor(0.4946)\n",
      "######### METRICS AFTER TRAINING EPOCH #########\n",
      "Epoch 19, Train F1 score: 0.7526, Train IoU: 0.6395, Val F1 score: 0.6294, Val IoU: 0.5269\n",
      "Train F1 score for each class: [0.89754796 0.47658223 0.8837062 ], \n",
      "Train IoU for each class: [0.8141377  0.3128375  0.79164314]\n",
      "Test FAR: 0.1552\n",
      "Test F1 score for each class: [0.84664285 0.18999986 0.85162467], \n",
      "Test IoU for each class: [0.7340681  0.10497229 0.7415909 ]\n",
      "best model is on epoch = 19\n",
      " model updated\n",
      "epoch_n = 20\n",
      "-----------training process---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 381/381 [05:43<00:00,  1.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after training epoch mean train loss = tensor(0.4849)\n",
      "-----------validation process---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 74/74 [00:29<00:00,  2.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid loss = tensor(0.4925)\n",
      "######### METRICS AFTER TRAINING EPOCH #########\n",
      "Epoch 20, Train F1 score: 0.7566, Train IoU: 0.6435, Val F1 score: 0.6095, Val IoU: 0.5175\n",
      "Train F1 score for each class: [0.89946115 0.48687655 0.8835707 ], \n",
      "Train IoU for each class: [0.8172918  0.32176924 0.7914255 ]\n",
      "Test FAR: 0.1507\n",
      "Test F1 score for each class: [0.8472576  0.12303608 0.85832393], \n",
      "Test IoU for each class: [0.73499304 0.06555058 0.7518104 ]\n",
      "epoch_n = 21\n",
      "-----------training process---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|███████████████████████████████████████████████▊                                | 228/381 [03:25<02:15,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "** Ranger21 update: Warmdown starting now.  Current iteration = 8229....\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 381/381 [05:43<00:00,  1.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after training epoch mean train loss = tensor(0.4851)\n",
      "-----------validation process---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 74/74 [00:29<00:00,  2.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid loss = tensor(0.4918)\n",
      "######### METRICS AFTER TRAINING EPOCH #########\n",
      "Epoch 21, Train F1 score: 0.7608, Train IoU: 0.6469, Val F1 score: 0.6386, Val IoU: 0.5356\n",
      "Train F1 score for each class: [0.8976804  0.500416   0.88430244], \n",
      "Train IoU for each class: [0.8143559  0.33370322 0.7926005 ]\n",
      "Test FAR: 0.1496\n",
      "Test F1 score for each class: [0.8499689  0.2075715  0.85837024], \n",
      "Test IoU for each class: [0.7390834  0.11580462 0.7518814 ]\n",
      "best model is on epoch = 21\n",
      " model updated\n",
      "epoch_n = 22\n",
      "-----------training process---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 381/381 [05:46<00:00,  1.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after training epoch mean train loss = tensor(0.4840)\n",
      "-----------validation process---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 74/74 [00:28<00:00,  2.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid loss = tensor(0.4902)\n",
      "######### METRICS AFTER TRAINING EPOCH #########\n",
      "Epoch 22, Train F1 score: 0.7609, Train IoU: 0.6480, Val F1 score: 0.6274, Val IoU: 0.5305\n",
      "Train F1 score for each class: [0.90055865 0.49649936 0.88564694], \n",
      "Train IoU for each class: [0.8191057 0.3302289 0.7947634]\n",
      "Test FAR: 0.1466\n",
      "Test F1 score for each class: [0.8467037  0.1684154  0.86717516], \n",
      "Test IoU for each class: [0.73415977 0.09195065 0.765498  ]\n",
      "epoch_n = 23\n",
      "-----------training process---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 381/381 [05:44<00:00,  1.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after training epoch mean train loss = tensor(0.4832)\n",
      "-----------validation process---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 74/74 [00:29<00:00,  2.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid loss = tensor(0.4927)\n",
      "######### METRICS AFTER TRAINING EPOCH #########\n",
      "Epoch 23, Train F1 score: 0.7646, Train IoU: 0.6520, Val F1 score: 0.6290, Val IoU: 0.5292\n",
      "Train F1 score for each class: [0.9012998 0.5047895 0.8877366], \n",
      "Train IoU for each class: [0.82033277 0.33760428 0.7981352 ]\n",
      "Test FAR: 0.1507\n",
      "Test F1 score for each class: [0.8499105  0.18011056 0.85685354], \n",
      "Test IoU for each class: [0.73899513 0.09896786 0.7495572 ]\n",
      "epoch_n = 24\n",
      "-----------training process---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 381/381 [05:43<00:00,  1.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after training epoch mean train loss = tensor(0.4833)\n",
      "-----------validation process---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 74/74 [00:29<00:00,  2.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid loss = tensor(0.4939)\n",
      "######### METRICS AFTER TRAINING EPOCH #########\n",
      "Epoch 24, Train F1 score: 0.7656, Train IoU: 0.6526, Val F1 score: 0.6284, Val IoU: 0.5272\n",
      "Train F1 score for each class: [0.9015188  0.50901586 0.88630545], \n",
      "Train IoU for each class: [0.8206957  0.34139588 0.7958246 ]\n",
      "Test FAR: 0.1533\n",
      "Test F1 score for each class: [0.8475981  0.18364444 0.8538898 ], \n",
      "Test IoU for each class: [0.73550546 0.101106   0.74503297]\n",
      "epoch_n = 25\n",
      "-----------training process---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 381/381 [05:40<00:00,  1.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after training epoch mean train loss = tensor(0.4827)\n",
      "-----------validation process---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 74/74 [00:28<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid loss = tensor(0.4909)\n",
      "######### METRICS AFTER TRAINING EPOCH #########\n",
      "Epoch 25, Train F1 score: 0.7684, Train IoU: 0.6557, Val F1 score: 0.6331, Val IoU: 0.5336\n",
      "Train F1 score for each class: [0.9019317 0.5152307 0.8880538], \n",
      "Train IoU for each class: [0.8213804 0.3470106 0.7986482]\n",
      "Test FAR: 0.1474\n",
      "Test F1 score for each class: [0.8499129  0.18625589 0.8630005 ], \n",
      "Test IoU for each class: [0.73899865 0.10269138 0.75901574]\n",
      "epoch_n = 26\n",
      "-----------training process---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 381/381 [05:44<00:00,  1.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after training epoch mean train loss = tensor(0.4816)\n",
      "-----------validation process---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 74/74 [00:29<00:00,  2.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid loss = tensor(0.4919)\n",
      "######### METRICS AFTER TRAINING EPOCH #########\n",
      "Epoch 26, Train F1 score: 0.7702, Train IoU: 0.6585, Val F1 score: 0.6275, Val IoU: 0.5290\n",
      "Train F1 score for each class: [0.9039018  0.51557887 0.8910124 ], \n",
      "Train IoU for each class: [0.8246541  0.34732658 0.80344653]\n",
      "Test FAR: 0.1494\n",
      "Test F1 score for each class: [0.8495062  0.17332537 0.8596212 ], \n",
      "Test IoU for each class: [0.7383839  0.09488574 0.7538032 ]\n",
      "epoch_n = 27\n",
      "-----------training process---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 381/381 [05:42<00:00,  1.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after training epoch mean train loss = tensor(0.4816)\n",
      "-----------validation process---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 74/74 [00:29<00:00,  2.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid loss = tensor(0.4912)\n",
      "######### METRICS AFTER TRAINING EPOCH #########\n",
      "Epoch 27, Train F1 score: 0.7699, Train IoU: 0.6581, Val F1 score: 0.6337, Val IoU: 0.5336\n",
      "Train F1 score for each class: [0.9044793 0.515518  0.8897259], \n",
      "Train IoU for each class: [0.825616   0.34727132 0.801357  ]\n",
      "Test FAR: 0.1481\n",
      "Test F1 score for each class: [0.850517   0.18961555 0.8611071 ], \n",
      "Test IoU for each class: [0.73991257 0.10473772 0.7560913 ]\n",
      "epoch_n = 28\n",
      "-----------training process---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 381/381 [05:43<00:00,  1.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after training epoch mean train loss = tensor(0.4813)\n",
      "-----------validation process---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 74/74 [00:29<00:00,  2.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid loss = tensor(0.4916)\n",
      "######### METRICS AFTER TRAINING EPOCH #########\n",
      "Epoch 28, Train F1 score: 0.7718, Train IoU: 0.6601, Val F1 score: 0.6328, Val IoU: 0.5326\n",
      "Train F1 score for each class: [0.9035033  0.51979727 0.8920719 ], \n",
      "Train IoU for each class: [0.8239907  0.35116625 0.80517125]\n",
      "Test FAR: 0.1488\n",
      "Test F1 score for each class: [0.850852   0.18797576 0.85957956], \n",
      "Test IoU for each class: [0.74041986 0.103738   0.75373936]\n",
      "epoch_n = 29\n",
      "-----------training process---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 381/381 [05:43<00:00,  1.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error in warmdown - lr below min lr. current lr = 2.999999999999997e-05\n",
      "auto handling but please report issue!\n",
      "after training epoch mean train loss = tensor(0.4815)\n",
      "-----------validation process---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 74/74 [00:29<00:00,  2.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid loss = tensor(0.4920)\n",
      "######### METRICS AFTER TRAINING EPOCH #########\n",
      "Epoch 29, Train F1 score: 0.7717, Train IoU: 0.6597, Val F1 score: 0.6319, Val IoU: 0.5317\n",
      "Train F1 score for each class: [0.90449065 0.5208447  0.8896654 ], \n",
      "Train IoU for each class: [0.82563484 0.35212305 0.8012589 ]\n",
      "Test FAR: 0.1494\n",
      "Test F1 score for each class: [0.8500447  0.18663645 0.858999  ], \n",
      "Test IoU for each class: [0.7391981  0.10292279 0.75284684]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# continue finetunning training process on ELECTRO L2 ds with Ranger21 optimizer\n",
    "from ranger21 import Ranger21\n",
    "max_ep_num = 3\n",
    "best_valid_iou_ = 0.5\n",
    "cur_ep = 0\n",
    "lr, weight_decay = 1e-3, 1e-4\n",
    "#optimizer = optim.AdamW(model.parameters(),lr = 1e-3)\n",
    "#scheduler = CosineAnnealingLR(optimizer, T_max=max_ep_num)\n",
    "optimizer_Ranger21 =  Ranger21(model.parameters(), lr = lr, weight_decay = weight_decay,\n",
    "                                num_epochs = max_ep_num,num_batches_per_epoch = len(train_dl_))\n",
    "model.train()\n",
    "dice = smp.losses.DiceLoss(mode= 'multiclass')\n",
    "focal = smp.losses.FocalLoss(mode= 'multiclass', gamma = 2)\n",
    "focal_alpha = 0.7\n",
    "tr_f1_,val_f1_,tr_iou_, val_iou_,tr_loss_,val_loss_ = [],[],[],[best_valid_iou_],[],[]\n",
    "for ep_i in range(cur_ep,cur_ep+max_ep_num):\n",
    "    train_f1_,train_iou_,valid_f1_,valid_iou_,train_loss_,valid_loss_= train_ep(model, train_dl_, valid_dl_, dice, focal,focal_alpha,optimizer_Ranger21,ep_i,best_valid_iou_,scheduler=None)\n",
    "    tr_f1_.append(train_f1_)\n",
    "    val_f1_.append(valid_f1_)\n",
    "    tr_iou_.append(train_iou_)\n",
    "    val_iou_.append(valid_iou_)\n",
    "    best_valid_iou_ = max(val_iou_)\n",
    "    tr_loss_.append(train_loss_)\n",
    "    val_loss_.append(valid_loss_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae75993",
   "metadata": {},
   "source": [
    "## BLENDING SEVERAL MODELS via MODELS.SOUP TO RAISE QUALITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "5f700005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H:\\ELECTRO_DATASET\\4_km_res\\L2/models/MAnet_Efficient_b0_12_inputs_4km_res_ep_216\n",
      "H:\\ELECTRO_DATASET\\4_km_res\\L2/models/MAnet_Efficient_b0_12_inputs_4km_res_ep_198\n",
      "H:\\ELECTRO_DATASET\\4_km_res\\L2/models/MAnet_Efficient_b0_12_inputs_4km_res_ep_175\n"
     ]
    }
   ],
   "source": [
    "# PREPARE A LIST OF SEVERAL MODELS WITH THE SAME ARCHITECTURE TO SOUP THEIR WEIGHTS\n",
    "model_path1 = '1st_model_dir'\n",
    "model_path2 = '2nd_model_dir'\n",
    "model_path3 = '3rd_model_dir'\n",
    "model_path_list = [model_path1,model_path2,model_path3]\n",
    "for i, model_path in enumerate(model_path_list):\n",
    "    print(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "39a8d566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Uniform Soup Performance]\n",
      "-----------Testing process---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [01:20<00:00,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test F1 score: 0.8077, Test IoU: 0.7432\n",
      "Test FAR: 0.1093\n",
      "Test F1 score for each class(bg, snow, cloud): [0.8006987  0.74544346 0.8768815 ], \n",
      "Test IoU for each class(bg, snow, cloud): [0.6924185 0.7397989 0.7972732]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def uniform_soup(model, path, device = \"cpu\", by_name = False):\n",
    "    try:\n",
    "        import torch\n",
    "    except:\n",
    "        print(\"If you want to use 'Model Soup for Torch', please install 'torch'\")\n",
    "        return model\n",
    "        \n",
    "    if not isinstance(path, list):\n",
    "        path = [path]\n",
    "    model = model.to(device)\n",
    "    model_dict = model.state_dict()\n",
    "    soups = {key:[] for key in model_dict}\n",
    "    for i, model_path in enumerate(path):\n",
    "        weight = torch.load(model_path, map_location = device)\n",
    "        weight_dict = weight.state_dict() if hasattr(weight, \"state_dict\") else weight\n",
    "        if by_name:\n",
    "            weight_dict = {k:v for k, v in weight_dict.items() if k in model_dict}\n",
    "        for k, v in weight_dict.items():\n",
    "            soups[k].append(v)\n",
    "    if 0 < len(soups):\n",
    "        soups = {k:(torch.sum(torch.stack(v), axis = 0) / len(v)).type(v[0].dtype) for k, v in soups.items() if len(v) != 0}\n",
    "        model_dict.update(soups)\n",
    "        model.load_state_dict(model_dict)\n",
    "    return model\n",
    "print(\"\\n[Uniform Soup Performance]\")\n",
    "souped_model = uniform_soup(model, model_path_list, device = device)\n",
    "# test_model(souped_model, valid_dl_)\n",
    "test_model(souped_model, test_dl_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "f40cc7c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "souped model saved!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MAnet(\n",
       "  (encoder): EfficientNetEncoder(\n",
       "    (_conv_stem): Conv2dStaticSamePadding(\n",
       "      12, 32, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
       "      (static_padding): ZeroPad2d((0, 1, 0, 1))\n",
       "    )\n",
       "    (_bn0): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    (_blocks): ModuleList(\n",
       "      (0): MBConvBlock(\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          32, 32, kernel_size=(3, 3), stride=[1, 1], groups=32, bias=False\n",
       "          (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          32, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          8, 32, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(16, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (1): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          96, 96, kernel_size=(3, 3), stride=[2, 2], groups=96, bias=False\n",
       "          (static_padding): ZeroPad2d((0, 1, 0, 1))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          96, 4, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          4, 96, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (2): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False\n",
       "          (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (3): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          144, 144, kernel_size=(5, 5), stride=[2, 2], groups=144, bias=False\n",
       "          (static_padding): ZeroPad2d((1, 2, 1, 2))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (4): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          240, 240, kernel_size=(5, 5), stride=(1, 1), groups=240, bias=False\n",
       "          (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (5): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          240, 240, kernel_size=(3, 3), stride=[2, 2], groups=240, bias=False\n",
       "          (static_padding): ZeroPad2d((0, 1, 0, 1))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (6-7): 2 x MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False\n",
       "          (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (8): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          480, 480, kernel_size=(5, 5), stride=[1, 1], groups=480, bias=False\n",
       "          (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (9-10): 2 x MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False\n",
       "          (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (11): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          672, 672, kernel_size=(5, 5), stride=[2, 2], groups=672, bias=False\n",
       "          (static_padding): ZeroPad2d((1, 2, 1, 2))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (12-14): 3 x MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
       "          (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (15): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1152, 1152, kernel_size=(3, 3), stride=[1, 1], groups=1152, bias=False\n",
       "          (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(320, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "    )\n",
       "    (_conv_head): Conv2dStaticSamePadding(\n",
       "      320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "      (static_padding): Identity()\n",
       "    )\n",
       "    (_bn1): BatchNorm2d(1280, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    (_avg_pooling): AdaptiveAvgPool2d(output_size=1)\n",
       "    (_dropout): Dropout(p=0.2, inplace=False)\n",
       "    (_swish): MemoryEfficientSwish()\n",
       "  )\n",
       "  (decoder): MAnetDecoder(\n",
       "    (center): PAB(\n",
       "      (top_conv): Conv2d(320, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (center_conv): Conv2d(320, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bottom_conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (map_softmax): Softmax(dim=1)\n",
       "      (out_conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (blocks): ModuleList(\n",
       "      (0): MFAB(\n",
       "        (hl_conv): Sequential(\n",
       "          (0): Conv2dReLU(\n",
       "            (0): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dReLU(\n",
       "            (0): Conv2d(320, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (SE_ll): Sequential(\n",
       "          (0): AdaptiveAvgPool2d(output_size=1)\n",
       "          (1): Conv2d(112, 7, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(7, 112, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (4): Sigmoid()\n",
       "        )\n",
       "        (SE_hl): Sequential(\n",
       "          (0): AdaptiveAvgPool2d(output_size=1)\n",
       "          (1): Conv2d(112, 7, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(7, 112, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (4): Sigmoid()\n",
       "        )\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(224, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (1): MFAB(\n",
       "        (hl_conv): Sequential(\n",
       "          (0): Conv2dReLU(\n",
       "            (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dReLU(\n",
       "            (0): Conv2d(256, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (SE_ll): Sequential(\n",
       "          (0): AdaptiveAvgPool2d(output_size=1)\n",
       "          (1): Conv2d(40, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(2, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (4): Sigmoid()\n",
       "        )\n",
       "        (SE_hl): Sequential(\n",
       "          (0): AdaptiveAvgPool2d(output_size=1)\n",
       "          (1): Conv2d(40, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(2, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (4): Sigmoid()\n",
       "        )\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(80, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (2): MFAB(\n",
       "        (hl_conv): Sequential(\n",
       "          (0): Conv2dReLU(\n",
       "            (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dReLU(\n",
       "            (0): Conv2d(128, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (SE_ll): Sequential(\n",
       "          (0): AdaptiveAvgPool2d(output_size=1)\n",
       "          (1): Conv2d(24, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(1, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (4): Sigmoid()\n",
       "        )\n",
       "        (SE_hl): Sequential(\n",
       "          (0): AdaptiveAvgPool2d(output_size=1)\n",
       "          (1): Conv2d(24, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(1, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (4): Sigmoid()\n",
       "        )\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(48, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (3): MFAB(\n",
       "        (hl_conv): Sequential(\n",
       "          (0): Conv2dReLU(\n",
       "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dReLU(\n",
       "            (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (SE_ll): Sequential(\n",
       "          (0): AdaptiveAvgPool2d(output_size=1)\n",
       "          (1): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(2, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (4): Sigmoid()\n",
       "        )\n",
       "        (SE_hl): Sequential(\n",
       "          (0): AdaptiveAvgPool2d(output_size=1)\n",
       "          (1): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(2, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (4): Sigmoid()\n",
       "        )\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (4): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (segmentation_head): SegmentationHead(\n",
       "    (0): Conv2d(16, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): Identity()\n",
       "    (2): Activation(\n",
       "      (activation): Identity()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def save_souped_model(model,num_models=3, path =  r'H:\\ELECTRO_DATASET\\4_km_res\\L2/models/MAnet_Efficient_b0_12_inputs_4km_res_souped'):\n",
    "        model_copy = deepcopy(model)\n",
    "        best_model = model_copy\n",
    "        best_model_name = path+'_3_models'\n",
    "        torch.save(best_model.state_dict(),best_model_name)\n",
    "        print('souped model saved!')\n",
    "        return best_model\n",
    "save_souped_model(souped_model)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "celltoolbar": "Raw Cell Format",
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "04b774be51d54e5dbe30cd67ea31e622": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a90d604aa1764e569754a2e6ba4f41c8",
      "placeholder": "​",
      "style": "IPY_MODEL_2cdafeca487e41c6820a7632d8411593",
      "value": "100%"
     }
    },
    "0ceccf3c8f7746e09357e26bbc2c84a1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1858ca8d33de4f6dac7f14ffa6177298": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "27f1a26db04f4a3fb2d6cc9e31dfe8cc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2cdafeca487e41c6820a7632d8411593": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "53ff3c47b09a45b886f998d41eb73cb9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1858ca8d33de4f6dac7f14ffa6177298",
      "max": 36804509,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0ceccf3c8f7746e09357e26bbc2c84a1",
      "value": 36804509
     }
    },
    "676ba5cb97dd4da78395e2a711388bc0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "71bf8aeebddf49fa902f5cbb4e977ae2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f39d3cbbe44a453a99169236468e7a19",
      "placeholder": "​",
      "style": "IPY_MODEL_676ba5cb97dd4da78395e2a711388bc0",
      "value": " 35.1M/35.1M [00:00&lt;00:00, 110MB/s]"
     }
    },
    "8301d0859a154f0a951b6769c6ae6fbc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_04b774be51d54e5dbe30cd67ea31e622",
       "IPY_MODEL_53ff3c47b09a45b886f998d41eb73cb9",
       "IPY_MODEL_71bf8aeebddf49fa902f5cbb4e977ae2"
      ],
      "layout": "IPY_MODEL_27f1a26db04f4a3fb2d6cc9e31dfe8cc"
     }
    },
    "a90d604aa1764e569754a2e6ba4f41c8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f39d3cbbe44a453a99169236468e7a19": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
